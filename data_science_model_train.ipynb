{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"DataScience_salaries_2024.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "df.isna().sum()\n",
    "df.duplicated().sum()\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.duplicated().sum()\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(columns=[\"salary\",\"salary_currency\"],inplace=True)\n",
    "\n",
    "# ['work_year', 'experience_level', 'employment_type', 'job_title', 'salary_in_usd', 'employee_residence','remote_ratio', 'company_location', 'company_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['employment_type'].unique()\n",
    "# df['job_title'].unique()\n",
    "# df['company_size'].unique()\n",
    "# emp_res_set = set(df['employee_residence'].unique())\n",
    "# comp_loc_set = set(df['company_location'].unique())\n",
    "# len(emp_res_set)  # 88\n",
    "# len(comp_loc_set) # 77\n",
    "# comp_loc_set.issubset(emp_res_set)\n",
    "# resU = emp_res_set.union(comp_loc_set)\n",
    "# len(resU)  # 90\n",
    "# TWO ENTRIES ARE EXTRA, CHECK WHICH ARE THOSE\n",
    "\n",
    "# resD = resU.difference(emp_res_set)\n",
    "# resD  # {'BS', 'GI'}\n",
    "\n",
    "# dBSf = df[df[\"company_location\"] == \"BS\"]\n",
    "# dGIf = df[df[\"company_location\"] == \"GI\"]\n",
    "# print(len(dBSf))  # 1\n",
    "# print(len(dGIf))  # 1\n",
    "# print(len(df))\n",
    "\n",
    "# dBSf = df[df[\"employee_residence\"] == \"BS\"]\n",
    "# dGIf = df[df[\"employee_residence\"] == \"GI\"]\n",
    "# print(len(dBSf))  # 0\n",
    "# print(len(dGIf))  # 0\n",
    "# print(len(df))    # 9127\n",
    "\n",
    "# df = df[~df[\"company_location\"].isin([\"BS\", \"GI\"])]\n",
    "# len(df)  # 9125\n",
    "\n",
    "# ACTUALLY EMPLOYE LOCATIONS OF DIFFERENT COUNTRIES AND ALSO INCLUDES REMOTE WORKING LOCATIONS. SO IT IS BETTER TO AVOID EMPLOYEE LOCATION AND RETAIN COMPANY LOCATION\n",
    "df.drop(columns=[\"employee_residence\",\"index\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df['job_title'].nunique()) # 153\n",
    "# job_title_counts = df['job_title'].value_counts()\n",
    "# print(job_title_counts)\n",
    "# fildf = [i for i in job_title_counts.index if job_title_counts[i] > 1]\n",
    "# print(len(fildf)) # 133\n",
    "\n",
    "# All_Job_Title = set(df['job_title'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USED CHAT GPT TO SORT OUT SIMILAR JOBS TOGETHER TO REDUCE DIMENSION FOR BOTH JOB TITLE AND MAP COMPANY LOCATION ABBREVATION TO ACTUAL LOCATIONS\n",
    "\n",
    "job_title_map = {\n",
    "    'AI Architect': 'AI Architect',\n",
    "    'AI Developer': 'AI Engineer',\n",
    "    'AI Engineer': 'AI Engineer',\n",
    "    'AI Product Manager': 'AI Product Manager',\n",
    "    'AI Programmer': 'AI Engineer',\n",
    "    'AI Research Engineer': 'AI Research Engineer',\n",
    "    'AI Research Scientist': 'AI Research Scientist',\n",
    "    'AI Scientist': 'AI Scientist',\n",
    "    'AI Software Engineer': 'AI Engineer',\n",
    "    'AWS Data Architect': 'Cloud Data Architect',\n",
    "    'Admin & Data Analyst': 'Data Analyst',\n",
    "    'Analytics Engineer': 'Analytics Engineer',\n",
    "    'Analytics Engineering Manager': 'Analytics Engineering Manager',\n",
    "    'Applied Data Scientist': 'Applied Data Scientist',\n",
    "    'Applied Machine Learning Engineer': 'Applied Machine Learning Engineer',\n",
    "    'Applied Machine Learning Scientist': 'Applied Machine Learning Scientist',\n",
    "    'Applied Research Scientist': 'Applied Research Scientist',\n",
    "    'Applied Scientist': 'Applied Scientist',\n",
    "    'Autonomous Vehicle Technician': 'Autonomous Vehicle Technician',\n",
    "    'Azure Data Engineer': 'Cloud Data Engineer',\n",
    "    'BI Analyst': 'Business Intelligence Analyst',\n",
    "    'BI Data Analyst': 'Business Intelligence Analyst',\n",
    "    'BI Data Engineer': 'BI Engineer',\n",
    "    'BI Developer': 'Business Intelligence Developer',\n",
    "    'Big Data Architect': 'Big Data Architect',\n",
    "    'Big Data Developer': 'Big Data Developer',\n",
    "    'Big Data Engineer': 'Big Data Engineer',\n",
    "    'Business Data Analyst': 'Business Intelligence Analyst',\n",
    "    'Business Intelligence': 'Business Intelligence',\n",
    "    'Business Intelligence Analyst': 'Business Intelligence Analyst',\n",
    "    'Business Intelligence Data Analyst': 'Business Intelligence Analyst',\n",
    "    'Business Intelligence Developer': 'Business Intelligence Developer',\n",
    "    'Business Intelligence Engineer': 'Business Intelligence Engineer',\n",
    "    'Business Intelligence Lead': 'Business Intelligence Lead',\n",
    "    'Business Intelligence Manager': 'Business Intelligence Manager',\n",
    "    'Business Intelligence Specialist': 'Business Intelligence Specialist',\n",
    "    'CRM Data Analyst': 'Data Analyst',\n",
    "    'Cloud Data Architect': 'Cloud Data Architect',\n",
    "    'Cloud Data Engineer': 'Cloud Data Engineer',\n",
    "    'Cloud Database Engineer': 'Cloud Data Engineer',\n",
    "    'Compliance Data Analyst': 'Data Analyst',\n",
    "    'Computational Biologist': 'Computational Biologist',\n",
    "    'Computer Vision Engineer': 'Computer Vision Engineer',\n",
    "    'Computer Vision Software Engineer': 'Computer Vision Engineer',\n",
    "    'Consultant Data Engineer': 'Data Engineer',\n",
    "    'Data Analyst': 'Data Analyst',\n",
    "    'Data Analyst Lead': 'Lead Data Analyst',\n",
    "    'Data Analytics Associate': 'Data Analyst',\n",
    "    'Data Analytics Consultant': 'Data Analyst',\n",
    "    'Data Analytics Engineer': 'Data Engineer',\n",
    "    'Data Analytics Lead': 'Lead Data Analyst',\n",
    "    'Data Analytics Manager': 'Data Analytics Manager',\n",
    "    'Data Analytics Specialist': 'Data Analyst',\n",
    "    'Data Architect': 'Data Architect',\n",
    "    'Data DevOps Engineer': 'Data Engineer',\n",
    "    'Data Developer': 'Data Engineer',\n",
    "    'Data Engineer': 'Data Engineer',\n",
    "    'Data Infrastructure Engineer': 'Data Engineer',\n",
    "    'Data Integration Developer': 'Data Engineer',\n",
    "    'Data Integration Engineer': 'Data Engineer',\n",
    "    'Data Integration Specialist': 'Data Engineer',\n",
    "    'Data Lead': 'Lead Data Analyst',\n",
    "    'Data Management Analyst': 'Data Analyst',\n",
    "    'Data Management Consultant': 'Data Consultant',\n",
    "    'Data Management Specialist': 'Data Management Specialist',\n",
    "    'Data Manager': 'Data Manager',\n",
    "    'Data Modeler': 'Data Modeler',\n",
    "    'Data Modeller': 'Data Modeler',\n",
    "    'Data Operations Analyst': 'Data Analyst',\n",
    "    'Data Operations Associate': 'Data Analyst',\n",
    "    'Data Operations Engineer': 'Data Engineer',\n",
    "    'Data Operations Manager': 'Data Manager',\n",
    "    'Data Operations Specialist': 'Data Analyst',\n",
    "    'Data Pipeline Engineer': 'Data Engineer',\n",
    "    'Data Product Manager': 'Data Product Manager',\n",
    "    'Data Product Owner': 'Data Product Manager',\n",
    "    'Data Quality Analyst': 'Data Analyst',\n",
    "    'Data Quality Engineer': 'Data Quality Engineer',\n",
    "    'Data Quality Manager': 'Data Quality Manager',\n",
    "    'Data Reporting Analyst': 'Data Analyst',\n",
    "    'Data Science': 'Data Scientist',\n",
    "    'Data Science Analyst': 'Data Scientist',\n",
    "    'Data Science Consultant': 'Data Scientist',\n",
    "    'Data Science Director': 'Data Science Director',\n",
    "    'Data Science Engineer': 'Data Scientist',\n",
    "    'Data Science Lead': 'Data Science Lead',\n",
    "    'Data Science Manager': 'Data Science Manager',\n",
    "    'Data Science Practitioner': 'Data Scientist',\n",
    "    'Data Science Tech Lead': 'Data Science Lead',\n",
    "    'Data Scientist': 'Data Scientist',\n",
    "    'Data Scientist Lead': 'Lead Data Scientist',\n",
    "    'Data Specialist': 'Data Specialist',\n",
    "    'Data Strategist': 'Data Strategist',\n",
    "    'Data Strategy Manager': 'Data Science Manager',\n",
    "    'Data Visualization Analyst': 'Data Visualization Specialist',\n",
    "    'Data Visualization Engineer': 'Data Visualization Engineer',\n",
    "    'Data Visualization Specialist': 'Data Visualization Specialist',\n",
    "    'Decision Scientist': 'Data Scientist',\n",
    "    'Deep Learning Engineer': 'Deep Learning Engineer',\n",
    "    'Deep Learning Researcher': 'Deep Learning Engineer',\n",
    "    'Director of Data Science': 'Data Science Director',\n",
    "    'ETL Developer': 'ETL Engineer',\n",
    "    'ETL Engineer': 'ETL Engineer',\n",
    "    'Encounter Data Management Professional': 'Data Analyst',\n",
    "    'Finance Data Analyst': 'Data Analyst',\n",
    "    'Financial Data Analyst': 'Data Analyst',\n",
    "    'Head of Data': 'Head of Data Science',\n",
    "    'Head of Data Science': 'Head of Data Science',\n",
    "    'Head of Machine Learning': 'Head of Machine Learning',\n",
    "    'Insight Analyst': 'Data Analyst',\n",
    "    'Lead Data Analyst': 'Lead Data Analyst',\n",
    "    'Lead Data Engineer': 'Lead Data Engineer',\n",
    "    'Lead Data Scientist': 'Lead Data Scientist',\n",
    "    'Lead Machine Learning Engineer': 'Lead Machine Learning Engineer',\n",
    "    'ML Engineer': 'Machine Learning Engineer',\n",
    "    'ML Ops Engineer': 'MLOps Engineer',\n",
    "    'MLOps Engineer': 'MLOps Engineer',\n",
    "    'Machine Learning Developer': 'Machine Learning Engineer',\n",
    "    'Machine Learning Engineer': 'Machine Learning Engineer',\n",
    "    'Machine Learning Infrastructure Engineer': 'Machine Learning Engineer',\n",
    "    'Machine Learning Manager': 'Machine Learning Manager',\n",
    "    'Machine Learning Modeler': 'Machine Learning Engineer',\n",
    "    'Machine Learning Operations Engineer': 'MLOps Engineer',\n",
    "    'Machine Learning Research Engineer': 'Machine Learning Researcher',\n",
    "    'Machine Learning Researcher': 'Machine Learning Researcher',\n",
    "    'Machine Learning Scientist': 'Machine Learning Scientist',\n",
    "    'Machine Learning Software Engineer': 'Machine Learning Engineer',\n",
    "    'Machine Learning Specialist': 'Machine Learning Engineer',\n",
    "    'Manager Data Management': 'Data Management Manager',\n",
    "    'Managing Director Data Science': 'Data Science Director',\n",
    "    'Marketing Data Analyst': 'Data Analyst',\n",
    "    'Marketing Data Engineer': 'Data Engineer',\n",
    "    'Marketing Data Scientist': 'Data Scientist',\n",
    "    'NLP Engineer': 'NLP Engineer',\n",
    "    'Power BI Developer': 'BI Developer',\n",
    "    'Principal Data Analyst': 'Data Analyst',\n",
    "    'Principal Data Architect': 'Data Architect',\n",
    "    'Principal Data Engineer': 'Data Engineer',\n",
    "    'Principal Data Scientist': 'Data Scientist',\n",
    "    'Principal Machine Learning Engineer': 'Machine Learning Engineer',\n",
    "    'Product Data Analyst': 'Data Analyst',\n",
    "    'Prompt Engineer': 'Data Scientist',\n",
    "    'Quantitative Research Analyst': 'Data Analyst',\n",
    "    'Research Analyst': 'Data Analyst',\n",
    "    'Research Engineer': 'Data Scientist',\n",
    "    'Research Scientist': 'Data Scientist',\n",
    "    'Robotics Engineer': 'Robotics Engineer',\n",
    "    'Robotics Software Engineer': 'Robotics Engineer',\n",
    "    'Sales Data Analyst': 'Data Analyst',\n",
    "    'Software Data Engineer': 'Software Engineer',\n",
    "    'Staff Data Analyst': 'Lead Data Analyst',\n",
    "    'Staff Data Scientist': 'Lead Data Scientist',\n",
    "    'Staff Machine Learning Engineer': 'Machine Learning Engineer'\n",
    "}\n",
    "df['job_title'] = df['job_title'].map(job_title_map)\n",
    "# print(df['job_title'].nunique()) # 66\n",
    "\n",
    "job_title_counts = df['job_title'].value_counts()\n",
    "# print(job_title_counts)\n",
    "# print(job_title_counts.to_string())\n",
    "\n",
    "comp_loca = {\n",
    " 'CL': 'Chile',\n",
    " 'US': 'United States',\n",
    " 'HU': 'Hungary',\n",
    " 'JP': 'Japan',\n",
    " 'IN': 'India',\n",
    " 'ID': 'Indonesia',\n",
    " 'DE': 'Germany',\n",
    " 'CH': 'Switzerland',\n",
    " 'IL': 'Israel',\n",
    " 'SG': 'Singapore',\n",
    " 'AS': 'American Samoa',\n",
    " 'NO': 'Norway',\n",
    " 'TH': 'Thailand',\n",
    " 'PH': 'Philippines',\n",
    " 'CA': 'Canada',\n",
    " 'MX': 'Mexico',\n",
    " 'ZA': 'South Africa',\n",
    " 'HK': 'Hong Kong',\n",
    " 'TR': 'Turkey',\n",
    " 'GB': 'United Kingdom',\n",
    " 'QA': 'Qatar',\n",
    " 'AU': 'Australia',\n",
    " 'DK': 'Denmark',\n",
    " 'ES': 'Spain',\n",
    " 'FR': 'France',\n",
    " 'EG': 'Egypt',\n",
    " 'UA': 'Ukraine',\n",
    " 'RU': 'Russian Federation',\n",
    " 'PL': 'Poland',\n",
    " 'NZ': 'New Zealand',\n",
    " 'NG': 'Nigeria',\n",
    " 'PR': 'Puerto Rico',\n",
    " 'BR': 'Brazil',\n",
    " 'SA': 'Saudi Arabia',\n",
    " 'IE': 'Ireland',\n",
    " 'NL': 'Netherlands',\n",
    " 'CO': 'Colombia',\n",
    " 'SE': 'Sweden',\n",
    " 'BA': 'Bosnia and Herzegovina',\n",
    " 'AE': 'United Arab Emirates',\n",
    " 'LT': 'Lithuania',\n",
    " 'PT': 'Portugal',\n",
    " 'MU': 'Mauritius',\n",
    " 'CZ': 'Czechia',\n",
    " 'FI': 'Finland',\n",
    " 'IQ': 'Iraq',\n",
    " 'CN': 'China',\n",
    " 'AR': 'Argentina',\n",
    " 'HR': 'Croatia',\n",
    " 'SI': 'Slovenia',\n",
    " 'LB': 'Lebanon',\n",
    " 'AT': 'Austria',\n",
    " 'VN': 'Viet Nam',\n",
    " 'KE': 'Kenya',\n",
    " 'GR': 'Greece',\n",
    " 'BE': 'Belgium',\n",
    " 'MT': 'Malta',\n",
    " 'LV': 'Latvia',\n",
    " 'IT': 'Italy',\n",
    " 'GI': 'Gibraltar',\n",
    " 'RO': 'Romania',\n",
    " 'EE': 'Estonia',\n",
    " 'LU': 'Luxembourg',\n",
    " 'KR': 'Korea, Republic of',\n",
    " 'AM': 'Armenia',\n",
    " 'AD': 'Andorra',\n",
    " 'OM': 'Oman',\n",
    " 'CF': 'Central African Republic',\n",
    " 'PK': 'Pakistan',\n",
    " 'MY': 'Malaysia',\n",
    " 'GH': 'Ghana',\n",
    " 'HN': 'Honduras',\n",
    " 'MD': 'Moldova, Republic of',\n",
    " 'EC': 'Ecuador'\n",
    "}\n",
    "df['company_location'] = df['company_location'].map(comp_loca)\n",
    "\n",
    "job_fil_avo = [i for i in job_title_counts.index if job_title_counts[i] <= 10]\n",
    "# print(len(job_fil_avo)) # 26\n",
    "df = df[~df[\"job_title\"].isin(job_fil_avo)]\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(columns=\"index\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "# import pandas as pd\n",
    "\n",
    "# ord_encoder_exp_lev = OrdinalEncoder(categories=[['EN','MI','SE','EX']])\n",
    "# ord_encoder_com_siz = OrdinalEncoder(categories=[['S','L','M']])\n",
    "\n",
    "# one_encoder_job_tit = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
    "# one_encoder_com_loc = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
    "# one_encoder_emp_typ = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
    "\n",
    "# df['experience_level'] = ord_encoder_exp_lev.fit_transform(df[['experience_level']])\n",
    "# df['company_size'] = ord_encoder_com_siz.fit_transform(df[['company_size']])\n",
    "\n",
    "# dJTf = one_encoder_job_tit.fit_transform(df[['job_title']])\n",
    "# dCLf = one_encoder_com_loc.fit_transform(df[['company_location']])\n",
    "# dEPf = one_encoder_emp_typ.fit_transform(df[['employment_type']])\n",
    "\n",
    "# dJTf_columns = one_encoder_job_tit.get_feature_names_out()\n",
    "# dCLf_columns = one_encoder_com_loc.get_feature_names_out()\n",
    "# dEPf_columns = one_encoder_emp_typ.get_feature_names_out()\n",
    "\n",
    "# NdJTf = pd.DataFrame(dJTf, columns=dJTf_columns)\n",
    "# NdCLf = pd.DataFrame(dCLf, columns=dCLf_columns)\n",
    "# NdEPf = pd.DataFrame(dEPf, columns=dEPf_columns)\n",
    "\n",
    "# df.drop(columns=[\"company_location\", \"job_title\", \"employment_type\"], inplace=True)\n",
    "# df = pd.concat([df, NdJTf, NdCLf, NdEPf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "import pandas as pd\n",
    "\n",
    "prepr_sal = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('experience_level', OrdinalEncoder(categories=[['EN', 'MI', 'SE', 'EX']]), ['experience_level']),\n",
    "        ('company_size', OrdinalEncoder(categories=[['S', 'L', 'M']]), ['company_size']),\n",
    "        ('job_title', OneHotEncoder(sparse_output=False, drop='first'), ['job_title']),\n",
    "        ('company_location', OneHotEncoder(sparse_output=False, drop='first'), ['company_location']),\n",
    "        ('employment_type', OneHotEncoder(sparse_output=False, drop='first'), ['employment_type'])\n",
    "    ])\n",
    "\n",
    "df_trans = prepr_sal.fit_transform(df)\n",
    "\n",
    "job_title_columns = prepr_sal.transformers_[2][1].get_feature_names_out()\n",
    "company_location_columns = prepr_sal.transformers_[3][1].get_feature_names_out()\n",
    "employment_type_columns = prepr_sal.transformers_[4][1].get_feature_names_out()\n",
    "\n",
    "new_columns = ['experience_level', 'company_size'] + list(job_title_columns) + list(company_location_columns) + list(employment_type_columns)\n",
    "\n",
    "df_trans = pd.DataFrame(df_trans, columns=new_columns)\n",
    "df.drop(columns=[\"job_title\",\"company_location\",\"employment_type\",\"experience_level\",\"company_size\"],inplace=True)\n",
    "df = pd.concat((df,df_trans),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "\n",
    "y = df['salary_in_usd']\n",
    "x = df.drop(columns=\"salary_in_usd\")\n",
    "\n",
    "# M_feat_scaler = MinMaxScaler()\n",
    "# M_targ_scaler = MinMaxScaler()\n",
    "\n",
    "M_feat_scaler = StandardScaler()\n",
    "M_targ_scaler = StandardScaler()\n",
    "\n",
    "x_scaled = M_feat_scaler.fit_transform(x)\n",
    "y_scaled = M_targ_scaler.fit_transform(y.values.reshape(-1,1))\n",
    "y_scaled = y_scaled.reshape(-1,)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_scaled,y_scaled,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR REGRESSION SCORE :  0.30674735289356003\n",
      "LINEAR REGRESSION OVERFIT SCORE :  0.31643275136616966\n",
      "MSE LINEAR REGRESSION :  [0.66849397]\n",
      "R2 SCORE LINEAR REGRESSION :  [0.30674735]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "L_Model = LinearRegression()\n",
    "L_Model.fit(x_train,y_train)\n",
    "score_L = L_Model.score(x_test,y_test)\n",
    "print(\"LINEAR REGRESSION SCORE : \",score_L)\n",
    "score_overfit = L_Model.score(x_train,y_train)\n",
    "print(\"LINEAR REGRESSION OVERFIT SCORE : \",score_overfit)\n",
    "\n",
    "y_pred = L_Model.predict(x_test)\n",
    "\n",
    "mse_L = mean_squared_error(y_test, y_pred, multioutput='raw_values')\n",
    "print(\"MSE LINEAR REGRESSION : \", mse_L)\n",
    "r2_L = r2_score(y_test, y_pred, multioutput='raw_values')\n",
    "print(\"R2 SCORE LINEAR REGRESSION : \",r2_L)\n",
    "\n",
    "# LINEAR REGRESSION MODEL FAILED CONSIDERABLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO REGRESSION SCORE: -0.00020971155890769921\n",
      "LASSO REGRESSION OVERFIT SCORE :  0.0\n",
      "LASSO REGRESSION MSE: 0.9644884407424285\n",
      "LASSO REGRESSION R2 SCORE: -0.00020971155890769921\n",
      "\n",
      "RIDGE REGRESSION SCORE: 0.306600008460056\n",
      "RIDGE REGRESSION OVERFIT SCORE :  0.316426158686377\n",
      "RIDGE REGRESSION MSE: 0.6686360559415403\n",
      "RIDGE REGRESSION R2 SCORE: 0.306600008460056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "lasso_model = Lasso(alpha=1)\n",
    "lasso_model.fit(x_train, y_train)\n",
    "score_lasso = lasso_model.score(x_test, y_test)\n",
    "print(\"LASSO REGRESSION SCORE:\", score_lasso)\n",
    "score_overfit = lasso_model.score(x_train,y_train)\n",
    "print(\"LASSO REGRESSION OVERFIT SCORE : \",score_overfit)\n",
    "\n",
    "y_pred_lasso = lasso_model.predict(x_test)\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "print(\"LASSO REGRESSION MSE:\", mse_lasso)\n",
    "print(\"LASSO REGRESSION R2 SCORE:\", r2_lasso,end=\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "ridge_model = Ridge(alpha=1)\n",
    "ridge_model.fit(x_train, y_train)\n",
    "score_ridge = ridge_model.score(x_test, y_test)\n",
    "print(\"RIDGE REGRESSION SCORE:\", score_ridge)\n",
    "score_overfit = ridge_model.score(x_train,y_train)\n",
    "print(\"RIDGE REGRESSION OVERFIT SCORE : \",score_overfit)\n",
    "\n",
    "y_pred_ridge = ridge_model.predict(x_test)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "print(\"RIDGE REGRESSION MSE:\", mse_ridge)\n",
    "print(\"RIDGE REGRESSION R2 SCORE:\", r2_ridge)\n",
    "\n",
    "# LASSO AND RIDGE PERFORMED BETTER THAN LINEAR REGRESSION, BUT IS ALSO A FAILURE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# poly = PolynomialFeatures(degree=2)\n",
    "# x_train_poly = poly.fit_transform(x_train)\n",
    "# x_test_poly = poly.transform(x_test)\n",
    "\n",
    "# P_Model = LinearRegression()\n",
    "# P_Model.fit(x_train_poly, y_train)\n",
    "\n",
    "# score_P = P_Model.score(x_test_poly, y_test)\n",
    "# print(\"POLYNOMIAL REGRESSION SCORE :\", score_P)\n",
    "\n",
    "# y_pred_poly = P_Model.predict(x_test_poly)\n",
    "\n",
    "# mse_P = mean_squared_error(y_test, y_pred_poly, multioutput='raw_values')\n",
    "# print(\"MSE POLYNOMIAL REGRESSION :\", mse_P)\n",
    "\n",
    "# r2_P = r2_score(y_test, y_pred_poly, multioutput='raw_values')\n",
    "# print(\"R2 SCORE POLYNOMIAL REGRESSION :\", r2_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR SCORE :  0.28475418195579183\n",
      "SVR OVERFIT SCORE :  0.2958967883852205\n",
      "SVR MSE: 0.6897016853773792\n",
      "SVR R2 SCORE: 0.28475418195579183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_model = SVR(kernel=\"linear\",C=.1)\n",
    "svr_model.fit(x_train,y_train)\n",
    "score = svr_model.score(x_test,y_test)\n",
    "print(\"SVR SCORE : \",score)\n",
    "score_overfit = svr_model.score(x_train,y_train)\n",
    "print(\"SVR OVERFIT SCORE : \",score_overfit)\n",
    "\n",
    "y_pred_svr = svr_model.predict(x_test)\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "print(\"SVR MSE:\", mse_svr)\n",
    "print(\"SVR R2 SCORE:\", r2_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST REGRESSOR SCORE : 0.2829634812730004\n",
      "RANDOM FOREST REGRESSOR OVERFIT SCORE :  0.4053106314659628\n",
      "RANDOM FOREST REGRESSOR MSE: 0.6914284333677482\n",
      "RANDOM FOREST REGRESSOR R2 SCORE: 0.2829634812730004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(x_train, y_train)\n",
    "score_rf = rf_model.score(x_test, y_test)\n",
    "print(\"RANDOM FOREST REGRESSOR SCORE :\", score_rf)\n",
    "score_overfit = rf_model.score(x_train,y_train)\n",
    "print(\"RANDOM FOREST REGRESSOR OVERFIT SCORE : \",score_overfit)\n",
    "\n",
    "y_pred_rf = rf_model.predict(x_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "print(\"RANDOM FOREST REGRESSOR MSE:\", mse_rf)\n",
    "print(\"RANDOM FOREST REGRESSOR R2 SCORE:\", r2_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRADIENT BOOSTING REGRESSOR SCORE : 0.3007434545497354\n",
      "GRADIENT BOOSTING REGRESSOR OVERFIT SCORE :  0.32571542842595336\n",
      "GRADIENT BOOSTING REGRESSOR MSE: 0.6742834501667825\n",
      "GRADIENT BOOSTING REGRESSOR R2 SCORE: 0.3007434545497354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "gb_model.fit(x_train, y_train)\n",
    "score_gb = gb_model.score(x_test, y_test)\n",
    "print(\"GRADIENT BOOSTING REGRESSOR SCORE :\", score_gb)\n",
    "score_overfit = gb_model.score(x_train,y_train)\n",
    "print(\"GRADIENT BOOSTING REGRESSOR OVERFIT SCORE : \",score_overfit)\n",
    "\n",
    "y_pred_gb = gb_model.predict(x_test)\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "print(\"GRADIENT BOOSTING REGRESSOR MSE:\", mse_gb)\n",
    "print(\"GRADIENT BOOSTING REGRESSOR R2 SCORE:\", r2_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN REGRESSOR SCORE : 0.1418554357914108\n",
      "KNN REGRESSOR OVERFIT SCORE :  0.23590120118781632\n",
      "KNN REGRESSOR MSE: 0.6897016853773792\n",
      "KNN REGRESSOR R2 SCORE: 0.28475418195579183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(x_train, y_train)\n",
    "score_knn = knn_model.score(x_test, y_test)\n",
    "print(\"KNN REGRESSOR SCORE :\", score_knn)\n",
    "score_overfit = knn_model.score(x_train,y_train)\n",
    "print(\"KNN REGRESSOR OVERFIT SCORE : \",score_overfit)\n",
    "\n",
    "y_pred_knn = svr_model.predict(x_test)\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "r2_knn = r2_score(y_test, y_pred_knn)\n",
    "print(\"KNN REGRESSOR MSE:\", mse_knn)\n",
    "print(\"KNN REGRESSOR R2 SCORE:\", r2_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESCISION TREE REGRESSOR SCORE : 0.24643490269254076\n",
      "DESCISION TREE REGRESSOR OVERFIT SCORE :  0.4143946467776921\n",
      "DESCISION TREE REGRESSOR MSE: 0.726652438284371\n",
      "DESCISION TREE REGRESSOR R2 SCORE: 0.24643490269254076\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model.fit(x_train, y_train)\n",
    "score_dt = dt_model.score(x_test, y_test)\n",
    "print(\"DESCISION TREE REGRESSOR SCORE :\", score_dt)\n",
    "score_overfit = dt_model.score(x_train,y_train)\n",
    "print(\"DESCISION TREE REGRESSOR OVERFIT SCORE : \",score_overfit)\n",
    "\n",
    "y_pred_dt = dt_model.predict(x_test)\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "r2_dt = r2_score(y_test, y_pred_dt)\n",
    "print(\"DESCISION TREE REGRESSOR MSE:\", mse_dt)\n",
    "print(\"DESCISION TREE REGRESSOR R2 SCORE:\", r2_dt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
